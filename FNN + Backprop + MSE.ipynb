{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanbrasdefer/GU_24_ANNs/blob/main/FNN%20%2B%20Backprop%20%2B%20MSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Set 1\n",
        "# Juan Pablo Brasdefer\n",
        "## September 2024\n",
        "## Applied Neural Networks - prof. Ziogas"
      ],
      "metadata": {
        "id": "tj41Y2cDA8WD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WLiFRNh1CJER"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import losses\n",
        "from scipy.stats import norm\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredError\n",
        "from tensorflow.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmmbvd-4ED_v"
      },
      "source": [
        "Let's adapt this code to our own neural net\n",
        "\n",
        "Each output o1 and o2 is real between 0.0 and 1.0\n",
        "*   Learning rate : 0.2\n",
        "*   Loss : Mean Squarred Error\n",
        "*   Optimizer : Simple Gradient Descent\n",
        "*   Normalization : Sigmoid function (for hidden and output layers)\n",
        "*   Bias : not updatable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BbvNBKynG5gV"
      },
      "outputs": [],
      "source": [
        "# changing our network to have 3 inputs\n",
        "input_layer = Input(shape=(3,))\n",
        "\n",
        "# assigning our input constants to their nodes\n",
        "inputs = tf.constant([[0.2, 0.35, 0.5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "P47t1lqiyWXG"
      },
      "outputs": [],
      "source": [
        "# creating a new class with which to set our bias for layers\n",
        "class SetBias(tf.keras.constraints.Constraint):\n",
        "  \"\"\"Constrains bias 1 to be 0.35\"\"\"\n",
        "\n",
        "  def __init__(self, ref_value):\n",
        "    self.ref_value = ref_value\n",
        "\n",
        "  def __call__(self, bias):\n",
        "    bias_cst=tf.fill(bias.shape, self.ref_value)\n",
        "    return bias_cst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvG4ycQ_XfQD"
      },
      "source": [
        "# Some useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3dAsTvHlXr9l"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "def cross_entropy(y,y_pre):\n",
        "  loss=-np.sum(y*np.log(y_pre))\n",
        "  return loss/float(y_pre.shape[0])\n",
        "def logistic(x):\n",
        "  logistic=1/(1+np.exp(-x))\n",
        "  return logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "c7ohitE9h2pO"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "def cross_entropy(y,y_pre):\n",
        "  loss=-np.sum(y*np.log(y_pre))\n",
        "  return loss/float(y_pre.shape[0])\n",
        "def logistic(x):\n",
        "  logistic=1/(1+np.exp(-x))\n",
        "  return logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlGi42OsXyWc",
        "outputId": "2354bb5d-6731-4818-9c2c-be05af41dfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax in Python : [0.0190013  0.04228816 0.93871054]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([0.1, 0.9, 4.0])\n",
        "output=softmax(x)\n",
        "print('Softmax in Python :',output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEbfyRHBXygf",
        "outputId": "c0b8cbc3-3bca-4660-edc5-ee7653750700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistics fn : [0.75136507 0.77292847]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1.105905967, 1.224921404])\n",
        "output=logistic(x)\n",
        "print('logistics fn :',output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "zqSUpdv3iLuK"
      },
      "outputs": [],
      "source": [
        "loss_fn=tf.keras.losses.MeanSquaredError()\n",
        "y_pred = [[0.751365066, 0.772928476]]\n",
        "y_true = [[0.01, 0.99]]\n",
        "\n",
        "#loss = loss_fn( y_true,y_pred)\n",
        "#loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTe8Unad_KOI"
      },
      "source": [
        "#Create Layer1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "b3C0rkz2-UBa"
      },
      "outputs": [],
      "source": [
        "# initialize weights and biases for our layer input->hidden\n",
        "\n",
        "\n",
        "# Define the hidden layer\n",
        "dense_layer1 = layers.Dense(\n",
        "    units=2,  # hidden layer has 2 neurons\n",
        "    use_bias=True,  # use bias for hidden layer\n",
        "    activation=activations.sigmoid,  # ActivationFunction (AF) set to sigmoid\n",
        "    name='layer1',\n",
        "    input_shape=(3,) # 3 layers in input layer\n",
        ")\n",
        "\n",
        "# Define the weights and biases\n",
        "W1 = np.array(\n",
        "    [[0.15, 0.3],  # weights from input 1 to hidden layer (w1, w4)\n",
        "     [0.20, 0.40],  # weights from input 2 to hidden layer (w2, w5)\n",
        "     [0.60, 0.10]])  # weights from input 3 to hidden layer (w3, w6)\n",
        "\n",
        "b1 = np.array([0.85, 0.85])  # bias for the two neurons in our hidden layer\n",
        "\n",
        "# Set the weights and biases\n",
        "dense_layer1.build((None, 3))  # Build the layer with input shape\n",
        "dense_layer1.set_weights([W1, b1])  # Set weights and biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjKKeZ9fS0_l"
      },
      "source": [
        "#Create layer 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dVSJd6X8MOqU"
      },
      "outputs": [],
      "source": [
        "# We set weights and biases according to jp example\n",
        "setBias2=SetBias(0.6)\n",
        "\n",
        "W2 = np.array(\n",
        "    [[0.8, 0.45],  # weights from hidden1 to output layer (w7, w9)\n",
        "     [0.5, 0.7]])  # wweights from hidden2 to output layer (w8, w10)\n",
        "\n",
        "b2 = np.array([0.25,0.25])   # bias for the two neurons in our output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dense_layer2 = layers.Dense(units=2, # 2 neurons in output\n",
        "                            use_bias=True, # use bias for hidden layer\n",
        "                            activation=activations.sigmoid, # ActivationFunction (AF) set to sigmoid\n",
        "                            name='layer2',\n",
        "                            input_shape=(2,) # 2 neurons in hidden\n",
        "                            )\n",
        "\n",
        "\n",
        "# Set the weights and biases\n",
        "dense_layer2.build((None, 2))  # Build the layer with input shape\n",
        "dense_layer2.set_weights([W2, b2])  # Set weights and biases\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ7eridySMKo"
      },
      "source": [
        "# Create the jp Model :\n",
        "# Input => Layer1 => Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "wveY5XyWHj3y",
        "outputId": "aaf247c6-4033-45cb-a21f-4e21ffe8e77d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer2 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14\u001b[0m (56.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> (56.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14\u001b[0m (56.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> (56.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# changing our network to have 3 inputs\n",
        "layer_inputs = Input(shape=(3,))\n",
        "out_layer1=dense_layer1(layer_inputs)\n",
        "out_layer2=dense_layer2(out_layer1)\n",
        "jp_model=Model(layer_inputs,out_layer2)\n",
        "jp_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic-ybFtJM1EF",
        "outputId": "6ca51f02-8a69-4a34-a2f0-021a95174a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model out o1= 0.776774883 Model out o2= 0.754908800\n",
            "jp  out o1= 0.780000000 jp  out o2= 0.750000000\n"
          ]
        }
      ],
      "source": [
        "#test jp model\n",
        "model_o=jp_model(inputs)\n",
        "model_o1=model_o[0][0]\n",
        "model_o2=model_o[0][1]\n",
        "\n",
        "jp_o1=0.78\n",
        "jp_o2=0.75\n",
        "model_diff_o1 = model_o1-jp_o1\n",
        "model_diff_o2 = model_o2-jp_o2\n",
        "print('Model out o1= {0:.9f}'.format(model_o1)+ ' Model out o2= {0:.9f}'.format(model_o2))\n",
        "print('jp  out o1= {0:.9f}'.format(jp_o1)+ ' jp  out o2= {0:.9f}'.format(jp_o2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8vxiZbMYtyd"
      },
      "source": [
        "# Compile jp Model with loss=MeanSquarredError\n",
        "\n",
        "\n",
        "*   fit model on 1 input to see\n",
        "    gradients w1 to w6 on layer1 after 1 backpropagation\n",
        "*   fit model on a second input ( the same input) to see\n",
        "    gradients w7 to w10 on layer2 after 2 backpropagation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ZA3zd9XbDiIA"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "jp_model.compile(\n",
        "    loss=tf.keras.losses.MeanSquaredError(),  # MSE ean Squared Error as loss\n",
        "    optimizer=optimizers.SGD(learning_rate=0.2),  # new SGD optimizer with alpha = 0.2\n",
        "    metrics=['accuracy'])  # another metric\n",
        "\n",
        "#training dataset\n",
        "x_tr=np.vstack([inputs]*1)\n",
        "y_true=np.array([0.1, # our targets, o1 and\n",
        "                 0.9]) # o2\n",
        "y_tr=np.vstack([y_true]*1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "ddaEfQw2v0ID",
        "outputId": "d47c5f57-60b9-45ad-f75e-4508eb4d91b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.0000e+00 - loss: 0.2395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <Functional name=functional_5, built=True>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.models.model.Model.summary</b><br/>def summary(line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py</a>Prints a string summary of the network.\n",
              "\n",
              "Args:\n",
              "    line_length: Total length of printed lines\n",
              "        (e.g. set this to adapt the display to different\n",
              "        terminal window sizes).\n",
              "    positions: Relative or absolute positions of log elements\n",
              "        in each line. If not provided, becomes\n",
              "        `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
              "    print_fn: Print function to use. By default, prints to `stdout`.\n",
              "        If `stdout` doesn&#x27;t work in your environment, change to `print`.\n",
              "        It will be called on each line of the summary.\n",
              "        You can set it to a custom function\n",
              "        in order to capture the string summary.\n",
              "    expand_nested: Whether to expand the nested models.\n",
              "        Defaults to `False`.\n",
              "    show_trainable: Whether to show if a layer is trainable.\n",
              "        Defaults to `False`.\n",
              "    layer_range: a list or tuple of 2 strings,\n",
              "        which is the starting layer name and ending layer name\n",
              "        (both inclusive) indicating the range of layers to be printed\n",
              "        in summary. It also accepts regex patterns instead of exact\n",
              "        names. In this case, the start predicate will be\n",
              "        the first element that matches `layer_range[0]`\n",
              "        and the end predicate will be the last element\n",
              "        that matches `layer_range[1]`.\n",
              "        By default `None` considers all layers of the model.\n",
              "\n",
              "Raises:\n",
              "    ValueError: if `summary()` is called before the model is built.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 216);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "#Let's train on only one backpropagation\n",
        "jp_model.fit(x_tr,\n",
        "             y_tr,\n",
        "             epochs=1,\n",
        "             batch_size=1,\n",
        "             verbose=1,\n",
        "             validation_split=0.0)\n",
        "jp_model.summary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick Discussion:\n",
        "It makes me very happy to see the above loss of 0.2395 in the first iteration. This is what I got when I did it manually! I'm not as dumb as I look!"
      ],
      "metadata": {
        "id": "CsY602Ce1pmF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whix8rKj9FtY",
        "outputId": "c5894fe3-3285-440a-8cfd-b6130f551898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 0.2331\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(3, 2), dtype=float32, path=layer1/kernel>,\n",
              " <KerasVariable shape=(2,), dtype=float32, path=layer1/bias>,\n",
              " <KerasVariable shape=(2, 2), dtype=float32, path=layer2/kernel>,\n",
              " <KerasVariable shape=(2,), dtype=float32, path=layer2/bias>]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "#after 1 training (1 back propagation) Weights at step 1:\n",
        "jp_model.fit(x_tr,\n",
        "             y_tr, epochs=1,\n",
        "             batch_size=1,\n",
        "             verbose=1,\n",
        "             validation_split=0.0)\n",
        "jp_model.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_dXb9AuY-j"
      },
      "source": [
        "Run a second backward propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUVWFH07BNax",
        "outputId": "587ad77e-ecda-4b99-c6cb-2ebc21727fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2266\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasVariable shape=(3, 2), dtype=float32, path=layer1/kernel>,\n",
              " <KerasVariable shape=(2,), dtype=float32, path=layer1/bias>,\n",
              " <KerasVariable shape=(2, 2), dtype=float32, path=layer2/kernel>,\n",
              " <KerasVariable shape=(2,), dtype=float32, path=layer2/bias>]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "#after 2 training of 1 epoch of batch=1 (2 back propagations) Weights at step 2:\n",
        "jp_model.fit(x_tr,\n",
        "             y_tr,\n",
        "             epochs=1,\n",
        "             batch_size=1,\n",
        "             verbose=1,\n",
        "             validation_split=0.0)\n",
        "jp_model.trainable_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p9sPU4IurMO"
      },
      "source": [
        "# Train the model on 1000 epochs\n",
        "  The output should be close to [0.1, 0.9]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eShOW6ON88_5",
        "outputId": "5eb1220e-6eaa-47c3-a90b-fa7397e3f877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.2028 \n",
            "Epoch 2/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.1339 \n",
            "Epoch 3/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0805 \n",
            "Epoch 4/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0488 \n",
            "Epoch 5/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0314 \n",
            "Epoch 6/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0215 \n",
            "Epoch 7/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0156 \n",
            "Epoch 8/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0117  \n",
            "Epoch 9/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
            "Epoch 10/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0072 \n",
            "Epoch 11/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 \n",
            "Epoch 12/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048  \n",
            "Epoch 13/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0040  \n",
            "Epoch 14/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034  \n",
            "Epoch 15/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
            "Epoch 16/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025 \n",
            "Epoch 17/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 \n",
            "Epoch 18/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 19/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016  \n",
            "Epoch 20/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 21/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012  \n",
            "Epoch 22/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 \n",
            "Epoch 23/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6238e-04  \n",
            "Epoch 24/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5483e-04  \n",
            "Epoch 25/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6138e-04  \n",
            "Epoch 26/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.7985e-04\n",
            "Epoch 27/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0843e-04 \n",
            "Epoch 28/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4567e-04  \n",
            "Epoch 29/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9034e-04 \n",
            "Epoch 30/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4141e-04  \n",
            "Epoch 31/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9802e-04  \n",
            "Epoch 32/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5945e-04 \n",
            "Epoch 33/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2509e-04  \n",
            "Epoch 34/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9440e-04  \n",
            "Epoch 35/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6695e-04 \n",
            "Epoch 36/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4234e-04  \n",
            "Epoch 37/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2024e-04 \n",
            "Epoch 38/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0036e-04  \n",
            "Epoch 39/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8245e-04 \n",
            "Epoch 40/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6630e-04  \n",
            "Epoch 41/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5170e-04 \n",
            "Epoch 42/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3850e-04 \n",
            "Epoch 43/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2654e-04 \n",
            "Epoch 44/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1570e-04 \n",
            "Epoch 45/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0586e-04 \n",
            "Epoch 46/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6919e-05 \n",
            "Epoch 47/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8787e-05  \n",
            "Epoch 48/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1385e-05 \n",
            "Epoch 49/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4641e-05  \n",
            "Epoch 50/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8491e-05 \n",
            "Epoch 51/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2879e-05  \n",
            "Epoch 52/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7754e-05 \n",
            "Epoch 53/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3071e-05 \n",
            "Epoch 54/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8788e-05 \n",
            "Epoch 55/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4869e-05  \n",
            "Epoch 56/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1281e-05  \n",
            "Epoch 57/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7993e-05 \n",
            "Epoch 58/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4980e-05 \n",
            "Epoch 59/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2217e-05  \n",
            "Epoch 60/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9682e-05  \n",
            "Epoch 61/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7354e-05 \n",
            "Epoch 62/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5216e-05  \n",
            "Epoch 63/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3252e-05  \n",
            "Epoch 64/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1446e-05  \n",
            "Epoch 65/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9786e-05  \n",
            "Epoch 66/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8259e-05 \n",
            "Epoch 67/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6854e-05 \n",
            "Epoch 68/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5560e-05 \n",
            "Epoch 69/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4369e-05 \n",
            "Epoch 70/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3271e-05 \n",
            "Epoch 71/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2260e-05 \n",
            "Epoch 72/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1328e-05  \n",
            "Epoch 73/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0469e-05 \n",
            "Epoch 74/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6765e-06 \n",
            "Epoch 75/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9456e-06 \n",
            "Epoch 76/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2712e-06 \n",
            "Epoch 77/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6488e-06 \n",
            "Epoch 78/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.0744e-06 \n",
            "Epoch 79/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5439e-06 \n",
            "Epoch 80/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0540e-06 \n",
            "Epoch 81/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6015e-06 \n",
            "Epoch 82/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1835e-06 \n",
            "Epoch 83/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7973e-06 \n",
            "Epoch 84/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4403e-06 \n",
            "Epoch 85/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1104e-06 \n",
            "Epoch 86/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8054e-06 \n",
            "Epoch 87/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5234e-06 \n",
            "Epoch 88/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2626e-06  \n",
            "Epoch 89/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0214e-06 \n",
            "Epoch 90/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7982e-06 \n",
            "Epoch 91/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5918e-06 \n",
            "Epoch 92/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4008e-06 \n",
            "Epoch 93/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2241e-06 \n",
            "Epoch 94/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0605e-06 \n",
            "Epoch 95/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9092e-06 \n",
            "Epoch 96/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7691e-06 \n",
            "Epoch 97/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6393e-06 \n",
            "Epoch 98/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5192e-06 \n",
            "Epoch 99/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4079e-06 \n",
            "Epoch 100/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3049e-06 \n",
            "Epoch 101/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2095e-06 \n",
            "Epoch 102/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1211e-06 \n",
            "Epoch 103/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0393e-06  \n",
            "Epoch 104/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6348e-07  \n",
            "Epoch 105/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9323e-07 \n",
            "Epoch 106/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2814e-07 \n",
            "Epoch 107/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6783e-07 \n",
            "Epoch 108/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1195e-07 \n",
            "Epoch 109/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.6016e-07 \n",
            "Epoch 110/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1217e-07 \n",
            "Epoch 111/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6768e-07 \n",
            "Epoch 112/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2648e-07 \n",
            "Epoch 113/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8825e-07 \n",
            "Epoch 114/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5283e-07 \n",
            "Epoch 115/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1999e-07 \n",
            "Epoch 116/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8954e-07 \n",
            "Epoch 117/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6133e-07 \n",
            "Epoch 118/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3515e-07  \n",
            "Epoch 119/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1088e-07 \n",
            "Epoch 120/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8838e-07 \n",
            "Epoch 121/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6752e-07 \n",
            "Epoch 122/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4818e-07 \n",
            "Epoch 123/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3023e-07 \n",
            "Epoch 124/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1360e-07 \n",
            "Epoch 125/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9818e-07 \n",
            "Epoch 126/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8386e-07 \n",
            "Epoch 127/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7059e-07 \n",
            "Epoch 128/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5827e-07 \n",
            "Epoch 129/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4685e-07 \n",
            "Epoch 130/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3626e-07 \n",
            "Epoch 131/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2643e-07 \n",
            "Epoch 132/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1731e-07 \n",
            "Epoch 133/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0886e-07 \n",
            "Epoch 134/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0102e-07 \n",
            "Epoch 135/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3741e-08 \n",
            "Epoch 136/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6982e-08 \n",
            "Epoch 137/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0711e-08 \n",
            "Epoch 138/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4901e-08 \n",
            "Epoch 139/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9508e-08 \n",
            "Epoch 140/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4512e-08 \n",
            "Epoch 141/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9863e-08 \n",
            "Epoch 142/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5559e-08 \n",
            "Epoch 143/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1559e-08 \n",
            "Epoch 144/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7848e-08 \n",
            "Epoch 145/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4414e-08 \n",
            "Epoch 146/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.1214e-08 \n",
            "Epoch 147/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8254e-08 \n",
            "Epoch 148/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5503e-08 \n",
            "Epoch 149/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2950e-08 \n",
            "Epoch 150/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0581e-08  \n",
            "Epoch 151/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8387e-08 \n",
            "Epoch 152/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6349e-08 \n",
            "Epoch 153/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4458e-08 \n",
            "Epoch 154/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2701e-08 \n",
            "Epoch 155/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1069e-08 \n",
            "Epoch 156/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9555e-08 \n",
            "Epoch 157/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8151e-08 \n",
            "Epoch 158/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6846e-08 \n",
            "Epoch 159/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5638e-08 \n",
            "Epoch 160/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4512e-08 \n",
            "Epoch 161/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3473e-08 \n",
            "Epoch 162/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2505e-08 \n",
            "Epoch 163/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1608e-08 \n",
            "Epoch 164/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0777e-08 \n",
            "Epoch 165/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0002e-08 \n",
            "Epoch 166/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2842e-09 \n",
            "Epoch 167/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.6189e-09 \n",
            "Epoch 168/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9995e-09 \n",
            "Epoch 169/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4242e-09 \n",
            "Epoch 170/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8946e-09 \n",
            "Epoch 171/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3996e-09 \n",
            "Epoch 172/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9396e-09 \n",
            "Epoch 173/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5125e-09 \n",
            "Epoch 174/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1197e-09 \n",
            "Epoch 175/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7526e-09 \n",
            "Epoch 176/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4124e-09 \n",
            "Epoch 177/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0940e-09 \n",
            "Epoch 178/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8022e-09 \n",
            "Epoch 179/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5305e-09 \n",
            "Epoch 180/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2760e-09 \n",
            "Epoch 181/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0416e-09 \n",
            "Epoch 182/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8224e-09 \n",
            "Epoch 183/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6195e-09 \n",
            "Epoch 184/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4350e-09 \n",
            "Epoch 185/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2599e-09 \n",
            "Epoch 186/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0981e-09 \n",
            "Epoch 187/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9475e-09 \n",
            "Epoch 188/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8077e-09 \n",
            "Epoch 189/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6762e-09 \n",
            "Epoch 190/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5591e-09 \n",
            "Epoch 191/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4479e-09 \n",
            "Epoch 192/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3441e-09 \n",
            "Epoch 193/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2475e-09 \n",
            "Epoch 194/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1588e-09 \n",
            "Epoch 195/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0762e-09 \n",
            "Epoch 196/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9844e-10 \n",
            "Epoch 197/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2453e-10 \n",
            "Epoch 198/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5795e-10 \n",
            "Epoch 199/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9914e-10 \n",
            "Epoch 200/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.4210e-10 \n",
            "Epoch 201/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.8888e-10 \n",
            "Epoch 202/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3946e-10 \n",
            "Epoch 203/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9334e-10 \n",
            "Epoch 204/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5233e-10 \n",
            "Epoch 205/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1320e-10 \n",
            "Epoch 206/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7640e-10 \n",
            "Epoch 207/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.4151e-10 \n",
            "Epoch 208/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0950e-10 \n",
            "Epoch 209/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7905e-10 \n",
            "Epoch 210/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5098e-10 \n",
            "Epoch 211/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2640e-10 \n",
            "Epoch 212/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0411e-10 \n",
            "Epoch 213/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8303e-10 \n",
            "Epoch 214/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6275e-10 \n",
            "Epoch 215/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4416e-10 \n",
            "Epoch 216/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2671e-10 \n",
            "Epoch 217/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1090e-10 \n",
            "Epoch 218/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9553e-10 \n",
            "Epoch 219/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8110e-10 \n",
            "Epoch 220/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6862e-10 \n",
            "Epoch 221/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5719e-10 \n",
            "Epoch 222/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4616e-10 \n",
            "Epoch 223/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3600e-10 \n",
            "Epoch 224/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2654e-10 \n",
            "Epoch 225/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1776e-10 \n",
            "Epoch 226/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0929e-10 \n",
            "Epoch 227/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0108e-10  \n",
            "Epoch 228/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3279e-11  \n",
            "Epoch 229/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.5970e-11  \n",
            "Epoch 230/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.9254e-11 \n",
            "Epoch 231/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2967e-11 \n",
            "Epoch 232/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.7326e-11 \n",
            "Epoch 233/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2479e-11 \n",
            "Epoch 234/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8253e-11  \n",
            "Epoch 235/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4355e-11  \n",
            "Epoch 236/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0846e-11  \n",
            "Epoch 237/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7608e-11 \n",
            "Epoch 238/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4389e-11  \n",
            "Epoch 239/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1340e-11  \n",
            "Epoch 240/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8813e-11  \n",
            "Epoch 241/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6130e-11  \n",
            "Epoch 242/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3907e-11  \n",
            "Epoch 243/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1767e-11  \n",
            "Epoch 244/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9601e-11  \n",
            "Epoch 245/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7559e-11 \n",
            "Epoch 246/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5756e-11 \n",
            "Epoch 247/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4185e-11 \n",
            "Epoch 248/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2560e-11 \n",
            "Epoch 249/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1020e-11 \n",
            "Epoch 250/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9504e-11  \n",
            "Epoch 251/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8156e-11 \n",
            "Epoch 252/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6837e-11 \n",
            "Epoch 253/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5634e-11 \n",
            "Epoch 254/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4494e-11 \n",
            "Epoch 255/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3287e-11 \n",
            "Epoch 256/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2226e-11 \n",
            "Epoch 257/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1249e-11 \n",
            "Epoch 258/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0253e-11 \n",
            "Epoch 259/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3321e-12  \n",
            "Epoch 260/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3775e-12 \n",
            "Epoch 261/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.6503e-12 \n",
            "Epoch 262/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2416e-12 \n",
            "Epoch 263/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9227e-12 \n",
            "Epoch 264/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5738e-12 \n",
            "Epoch 265/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2857e-12 \n",
            "Epoch 266/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.0056e-12 \n",
            "Epoch 267/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7378e-12 \n",
            "Epoch 268/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4920e-12 \n",
            "Epoch 269/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2461e-12 \n",
            "Epoch 270/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9762e-12 \n",
            "Epoch 271/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7977e-12 \n",
            "Epoch 272/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6610e-12 \n",
            "Epoch 273/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4840e-12  \n",
            "Epoch 274/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3408e-12 \n",
            "Epoch 275/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1848e-12 \n",
            "Epoch 276/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0313e-12 \n",
            "Epoch 277/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8948e-12 \n",
            "Epoch 278/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7459e-12 \n",
            "Epoch 279/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6179e-12 \n",
            "Epoch 280/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5116e-12 \n",
            "Epoch 281/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4982e-12 \n",
            "Epoch 282/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4420e-12 \n",
            "Epoch 283/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4064e-12 \n",
            "Epoch 284/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3440e-12 \n",
            "Epoch 285/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3306e-12 \n",
            "Epoch 286/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2645e-12 \n",
            "Epoch 287/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2286e-12 \n",
            "Epoch 288/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1768e-12 \n",
            "Epoch 289/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1420e-12  \n",
            "Epoch 290/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1081e-12 \n",
            "Epoch 291/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0716e-12 \n",
            "Epoch 292/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0220e-12  \n",
            "Epoch 293/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9746e-12 \n",
            "Epoch 294/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9613e-12 \n",
            "Epoch 295/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9204e-12 \n",
            "Epoch 296/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8800e-12 \n",
            "Epoch 297/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8278e-12 \n",
            "Epoch 298/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8056e-12 \n",
            "Epoch 299/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7632e-12 \n",
            "Epoch 300/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7420e-12 \n",
            "Epoch 301/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6876e-12 \n",
            "Epoch 302/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6676e-12 \n",
            "Epoch 303/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6261e-12  \n",
            "Epoch 304/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.6156e-12 \n",
            "Epoch 305/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5424e-12 \n",
            "Epoch 306/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5322e-12 \n",
            "Epoch 307/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4823e-12 \n",
            "Epoch 308/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4681e-12 \n",
            "Epoch 309/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4256e-12 \n",
            "Epoch 310/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4095e-12 \n",
            "Epoch 311/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3654e-12 \n",
            "Epoch 312/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3474e-12 \n",
            "Epoch 313/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3116e-12 \n",
            "Epoch 314/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2933e-12 \n",
            "Epoch 315/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2429e-12 \n",
            "Epoch 316/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.2219e-12 \n",
            "Epoch 317/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1913e-12 \n",
            "Epoch 318/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1825e-12  \n",
            "Epoch 319/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1365e-12 \n",
            "Epoch 320/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1148e-12 \n",
            "Epoch 321/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0838e-12 \n",
            "Epoch 322/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0685e-12 \n",
            "Epoch 323/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0340e-12 \n",
            "Epoch 324/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0050e-12 \n",
            "Epoch 325/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9755e-12 \n",
            "Epoch 326/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9532e-12 \n",
            "Epoch 327/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9400e-12 \n",
            "Epoch 328/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9112e-12 \n",
            "Epoch 329/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8913e-12 \n",
            "Epoch 330/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8625e-12 \n",
            "Epoch 331/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8511e-12 \n",
            "Epoch 332/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 333/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 334/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 335/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 336/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 337/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 338/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 339/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 340/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 341/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 342/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 343/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 344/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 345/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 346/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 347/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 348/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 349/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 350/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 351/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 352/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 353/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 354/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 355/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 356/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 357/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 358/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 359/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 360/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 361/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 362/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 363/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 364/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 365/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 366/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 367/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 368/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 369/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 370/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 371/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 372/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 373/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 374/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 375/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 376/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 377/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 378/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 379/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 380/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 381/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 382/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 383/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 384/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 385/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 386/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 387/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 388/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 389/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 390/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 391/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 392/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 393/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 394/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 395/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 396/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 397/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 398/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 399/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 400/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 401/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 402/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 403/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 404/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 405/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 406/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 407/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 408/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 409/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 410/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 411/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 412/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 413/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 414/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 415/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 416/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 417/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 418/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 419/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 420/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 421/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 422/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 423/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 424/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 425/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 426/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 427/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 428/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 429/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 430/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 431/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 432/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 433/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 434/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 435/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 436/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 437/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 438/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 439/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 440/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 441/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 442/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 443/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 444/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 445/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 446/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 447/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 448/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 449/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 450/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 451/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 452/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 453/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 454/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 455/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 456/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 457/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 458/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 459/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 460/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 461/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 462/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 463/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 464/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 465/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 466/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 467/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 468/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 469/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 470/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 471/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 472/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 473/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 474/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 475/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 476/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 477/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 478/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 479/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 480/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 481/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 482/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 483/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 484/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 485/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 486/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 487/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 488/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 489/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 490/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 491/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 492/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 493/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 494/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 495/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 496/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 497/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 498/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 499/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 500/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 501/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 502/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 503/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 504/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 505/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 506/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 507/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 508/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 509/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 510/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 511/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 512/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 513/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 514/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 515/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 516/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 517/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 518/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 519/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 520/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 521/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 522/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 523/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 524/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 525/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 526/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 527/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 528/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 529/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 530/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 531/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 532/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 533/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 534/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 535/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 536/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 537/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 538/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 539/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 540/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 541/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 542/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 543/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 544/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 545/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 546/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 547/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 548/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 549/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 550/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 551/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 552/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 553/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 554/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 555/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 556/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 557/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 558/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 559/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 560/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 561/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 562/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 563/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 564/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 565/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 566/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 567/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 568/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 569/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 570/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 571/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 572/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 573/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 574/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 575/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 576/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 577/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 578/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 579/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 580/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 581/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 582/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 583/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 584/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 585/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 586/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 587/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 588/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 589/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 590/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 591/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 592/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 593/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 594/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 595/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 596/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 597/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 598/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 599/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 600/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 601/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 602/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 603/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 604/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 605/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 606/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 607/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 608/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 609/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 610/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 611/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 612/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 613/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 614/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 615/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 616/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 617/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 618/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 619/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 620/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 621/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 622/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 623/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 624/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 625/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 626/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 627/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 628/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 629/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 630/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 631/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 632/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 633/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 634/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 635/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 636/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 637/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 638/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 639/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 640/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 641/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 642/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 643/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 644/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 645/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 646/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 647/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 648/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 649/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 650/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 651/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 652/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 653/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 654/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 655/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 656/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 657/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 658/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 659/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 660/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 661/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 662/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 663/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 664/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 665/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 666/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 667/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 668/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 669/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 670/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 671/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 672/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 673/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 674/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 675/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 676/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 677/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 678/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 679/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 680/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 681/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 682/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 683/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 684/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 685/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 686/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 687/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 688/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 689/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 690/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 691/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 692/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 693/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 694/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 695/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 696/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 697/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 698/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 699/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 700/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 701/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 702/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 703/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 704/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 705/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 706/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 707/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 708/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 709/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 710/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 711/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 712/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 713/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 714/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 715/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 716/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 717/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 718/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 719/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 720/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 721/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 722/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 723/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 724/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 725/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 726/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 727/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 728/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 729/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 730/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 731/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 732/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 733/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 734/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 735/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 736/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 737/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 738/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 739/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 740/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 741/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 742/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 743/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 744/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 745/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 746/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 747/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 748/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 749/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 750/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 751/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 752/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 753/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 754/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 755/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 756/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 757/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 758/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 759/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 760/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 761/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 762/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 763/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 764/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 765/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 766/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 767/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 768/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 769/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 770/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 771/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 772/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 773/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 774/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 775/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 776/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 777/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 778/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 779/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 780/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 781/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 782/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 783/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 784/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 785/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 786/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 787/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 788/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 789/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 790/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 791/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 792/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 793/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 794/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 795/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 796/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 797/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 798/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 799/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 800/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 801/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 802/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 803/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 804/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 805/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 806/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 807/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 808/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 809/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 810/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 811/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 812/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 813/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 814/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 815/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 816/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 817/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 818/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 819/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 820/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 821/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 822/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 823/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 824/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 825/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 826/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 827/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 828/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 829/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 830/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 831/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 832/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 833/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 834/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 835/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 836/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 837/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 838/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 839/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 840/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 841/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 842/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 843/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 844/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 845/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 846/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 847/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 848/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 849/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 850/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 851/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 852/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 853/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 854/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 855/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 856/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 857/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 858/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 859/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 860/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 861/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 862/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 863/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 864/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 865/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 866/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 867/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 868/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 869/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 870/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 871/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 872/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 873/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 874/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 875/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 876/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 877/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 878/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 879/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 880/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 881/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 882/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 883/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 884/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 885/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 886/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 887/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 888/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 889/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 890/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 891/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 892/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 893/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 894/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 895/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 896/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 897/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 898/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 899/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 900/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 901/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 902/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 903/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 904/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 905/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 906/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 907/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 908/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 909/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.8468e-12\n",
            "Epoch 910/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 911/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 912/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 913/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 914/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 915/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 916/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 917/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 918/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 919/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 920/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 921/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 922/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 923/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 924/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 925/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 926/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 927/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 928/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 929/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 930/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 931/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 932/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 933/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 934/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 935/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 936/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 937/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 938/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 939/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 940/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 941/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 942/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 943/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 944/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 945/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 946/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 947/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 948/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 949/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 950/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 951/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 952/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 953/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 954/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 955/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 956/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 957/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 958/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 959/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 960/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 961/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 962/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 963/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 964/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 965/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 966/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 967/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 968/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 969/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 970/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 971/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 972/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 973/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 974/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 975/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 976/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 977/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 978/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 979/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 980/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 981/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 982/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 983/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 984/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 985/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 986/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 987/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 988/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 989/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 990/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 991/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 992/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 993/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 994/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n",
            "Epoch 995/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 996/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 997/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 998/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 999/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12 \n",
            "Epoch 1000/1000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8468e-12  \n"
          ]
        }
      ],
      "source": [
        "#training dataset\n",
        "x_tr=np.vstack([inputs]*10)\n",
        "y_true=np.array([0.1,0.9])\n",
        "y_tr=np.vstack([y_true]*10)\n",
        "\n",
        "#Let's train on only one backpropagation\n",
        "history=jp_model.fit(x_tr,\n",
        "                     y_tr,\n",
        "                     epochs=1000,\n",
        "                     batch_size=1,\n",
        "                     verbose=1,\n",
        "                     validation_split=0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Error Assessment: MSE"
      ],
      "metadata": {
        "id": "T7IJq1n2_ZGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "YdFW8xCU7MCn",
        "outputId": "64527a08-1ff9-40dc-96d8-77b1a869fc61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize training process\n",
        "plt.plot(history.history['loss'],\n",
        "         label='Mean Squarred Error loss, learning rate : 0.2 (training data)')\n",
        "#plt.plot(history.history['accuracy'], label='accuracy (training data)')\n",
        "plt.title('MSE (Mean Squarred Loss)')\n",
        "plt.ylabel('loss value')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Num epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curiosity: Weights"
      ],
      "metadata": {
        "id": "pWCk56vq_ecX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SsJM-B889Ka",
        "outputId": "b2144dda-1047-4057-b09a-b13ee7fd8f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: kernel, Shape: (3, 2), Values: \n",
            "[[0.14943361 0.2997011 ]\n",
            " [0.19900881 0.3994769 ]\n",
            " [0.59858406 0.09925271]]\n",
            "\n",
            "Variable: kernel, Shape: (2, 2), Values: \n",
            "[[0.7817568  0.4541733 ]\n",
            " [0.48239142 0.7040281 ]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "jp_model.trainable_weights\n",
        "\n",
        "# inspect the 6 weights between first 2 layers\n",
        "# and 4 weights between hidden and output\n",
        "for var in jp_model.trainable_weights:\n",
        "    print(f\"Variable: {var.name}, Shape: {var.shape}, Values: \\n{var.numpy()}\\n\")\n",
        "\n",
        "# note that we see no bias!\n",
        "# since we prevented it from being altered"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the results here quickly\n"
      ],
      "metadata": {
        "id": "obBAYgYK_xq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGC6UeWAvPyx",
        "outputId": "e775fa32-126d-4ffc-8927-187cbde8d0e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.7719517, 0.7560345]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# let see the results\n",
        "jp_model(inputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2sxO1umvaK-"
      },
      "source": [
        "# jp Model : See the gradients\n",
        " We create a Custom training loop to see/update the gradients during training using GradientTape()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "WhTzoSLq0uX0"
      },
      "outputs": [],
      "source": [
        "# jps inputs\n",
        "inputs = tf.constant([[0.2, 0.35, 0.5]])\n",
        "batch_input=np.vstack([inputs]*3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the hidden layer\n",
        "dense_layer1 = layers.Dense(\n",
        "    units=2,  # hidden layer has 2 neurons\n",
        "    use_bias=True,  # use bias for hidden layer\n",
        "    activation=activations.sigmoid,  # ActivationFunction (AF) set to sigmoid\n",
        "    name='layer1',\n",
        "    input_shape=(3,) # 3 layers in input layer\n",
        ")\n",
        "\n",
        "# Define the weights and biases\n",
        "W1 = np.array(\n",
        "    [[0.15, 0.3],  # weights from input 1 to hidden layer (w1, w4)\n",
        "     [0.20, 0.40],  # weights from input 2 to hidden layer (w2, w5)\n",
        "     [0.60, 0.10]])  # weights from input 3 to hidden layer (w3, w6)\n",
        "\n",
        "b1 = np.array([0.85, 0.85])  # bias for the two neurons in our hidden layer\n",
        "\n",
        "# Set the weights and biases\n",
        "dense_layer1.build((None, 3))  # Build the layer with input shape\n",
        "dense_layer1.set_weights([W1, b1])  # Set weights and biases\n",
        "\n",
        "# We set weights and biases according to jp example\n",
        "setBias2=SetBias(0.6)\n",
        "\n",
        "W2 = np.array(\n",
        "    [[0.8, 0.45],  # weights from hidden1 to output layer (w7, w9)\n",
        "     [0.5, 0.7]])  # wweights from hidden2 to output layer (w8, w10)\n",
        "\n",
        "b2 = np.array([0.25,0.25])   # bias for the two neurons in our output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dense_layer2 = layers.Dense(units=2, # 2 neurons in output\n",
        "                            use_bias=True, # use bias for hidden layer\n",
        "                            activation=activations.sigmoid, # ActivationFunction (AF) set to sigmoid\n",
        "                            name='layer2',\n",
        "                            input_shape=(2,) # 2 neurons in hidden\n",
        "                            )\n",
        "\n",
        "\n",
        "# Set the weights and biases\n",
        "dense_layer2.build((None, 2))  # Build the layer with input shape\n",
        "dense_layer2.set_weights([W2, b2])  # Set weights and biases\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# changing our network to have 3 inputs\n",
        "layer_inputs = Input(shape=(3,))\n",
        "out_layer1=dense_layer1(layer_inputs)\n",
        "out_layer2=dense_layer2(out_layer1)\n",
        "jp_model=Model(layer_inputs,out_layer2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set biases to be non-trainable\n",
        "for layer in jp_model.layers:\n",
        "    if hasattr(layer, 'bias'):\n",
        "        layer.bias.trainable = False  # Make biases non-trainable\n",
        "\n",
        "# Compile the model\n",
        "jp_model.compile(\n",
        "    loss=tf.keras.losses.MeanSquaredError(),  # MSE ean Squared Error as loss\n",
        "    optimizer=optimizers.SGD(learning_rate=0.2),  # new SGD optimizer with alpha = 0.2\n",
        "    metrics=['accuracy'])  # another metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwB3T5BUBV1h",
        "outputId": "5f1ab048-c012-4c05-c401-c0a37bcdd25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradients [<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
            "array([[0.00283198, 0.00149459],\n",
            "       [0.00495597, 0.00261553],\n",
            "       [0.00707995, 0.00373648]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[ 0.091216  , -0.0208666 ],\n",
            "       [ 0.08804289, -0.02014072]], dtype=float32)>], \n",
            "      Loss : 0.2395378202199936\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# once again initializing our input vals\n",
        "x_tr = tf.constant([[0.2, 0.35, 0.5]])\n",
        "y_tr = tf.constant([[0.1, 0.9]]) # and targets\n",
        "\n",
        "# bring in data again\n",
        "xdataset = tf.data.Dataset.from_tensor_slices([x_tr])\n",
        "ydataset = tf.data.Dataset.from_tensor_slices([y_tr])\n",
        "tr_dataset = tf.data.Dataset.zip(xdataset, ydataset)\n",
        "\n",
        "\n",
        "loss_fn=tf.keras.losses.MeanSquaredError() # setting MSE\n",
        "optimizer_leg = optimizers.SGD(learning_rate=0.2) # learning rate\n",
        "\n",
        "# prof Ziogas gradient loop\n",
        "for (x, y_true) in tr_dataset:\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass.\n",
        "        y_pred = jp_model(x)\n",
        "        # Loss value for this batch of 1 input\n",
        "        loss = loss_fn( y_true,y_pred)\n",
        "\n",
        "    # Get gradients of the loss wrt the weights.\n",
        "    gradients = tape.gradient(loss, jp_model.trainable_weights)\n",
        "    trainable_weights=jp_model.trainable_weights\n",
        "    #Update the weights of our linear layer.\n",
        "    optimizer_leg.apply_gradients(zip(gradients, jp_model.trainable_weights))\n",
        "\n",
        "    # Logging.\n",
        "    print( f'gradients {gradients}, \\n      Loss : {float(loss)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eIwdHK9B6su",
        "outputId": "dff2dad0-5efe-4030-d0ca-226a8267b12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: kernel, Shape: (3, 2), Values: \n",
            "[[0.14943361 0.2997011 ]\n",
            " [0.19900881 0.3994769 ]\n",
            " [0.59858406 0.09925271]]\n",
            "\n",
            "Variable: kernel, Shape: (2, 2), Values: \n",
            "[[0.7817568  0.4541733 ]\n",
            " [0.48239142 0.7040281 ]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inspect weights again\n",
        "jp_model.trainable_weights\n",
        "\n",
        "for var in jp_model.trainable_weights:\n",
        "    print(f\"Variable: {var.name}, Shape: {var.shape}, Values: \\n{var.numpy()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n",
        "\n",
        "I think the most interesting part of this process was doing it myself first. Or, at least doing one full feed-forward, one full backpropagation, and one full weight-update.\n",
        "It took so long.\n",
        "So long.\n",
        "I know that computers are infinitely quicker than humans at logical processing tasks, but over the past three days I have been genuinely humbled. The calculations we had to do were themselves not very complex, but the brute force it took to multiply and derive and plug-in all those numbers by hand... I'm shocked.\n",
        "\n",
        "That is the largest point for me.\n",
        "\n",
        "Other ideas pertaining to the actual model and training are... somewhat bland perhaps. We trained the model on fixed inputs instead of across many observations, using a fixed batch size of 1 each time. If ever there was the possibility of a model overfitting, I would say we probably found it here today. Training a model in 1000 epochs to try to guess the same 2 outputs from the same 3 inputs is a pretty funny task. It was enjoyable to watch. Not sure I'd do it again!\n",
        "The MSE plot is also interesting. I don't have a super good intuition for why it bends the way it does (my guess would've been the log scale of the y-axis), but it has a strange few bends in the graph anyway... Maybe to be discussed in class!\n",
        "\n",
        "Either way, fun to apply the theory we've been speaking of for 5 weeks now, but I have to say that I've been reminded that I am much more a theory-inclined fella than practice. Coding this and watching the model run brought me no satisfaction even close to picking apart the partial derivatives and learning the theory in class. I guess it's good to have both.\n",
        "\n",
        "Disclaimer: Chat-GPT-4 was used in the modification and adaptation of this code."
      ],
      "metadata": {
        "id": "Zw7kB7vL8hHw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}